{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2dcfc-01bf-4be5-a6b1-6da084d6741a",
   "metadata": {},
   "source": [
    "# 1.什么是Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b767781e-6a09-4f82-a8cb-ad90c3c0f50c",
   "metadata": {},
   "source": [
    "Word2Vec是一种用于将词汇转换为向量表示的技术，它是自然语言处理中的一种重要工具。它的核心思想是将词汇映射到一个高维空间中的向量，使得具有相似含义的词汇在这个空间中的向量表示也相互靠近。这种表示能够捕捉到词汇之间的语义关系，例如近义词在向量空间中距离较近，而语义上不相关的词汇则距离较远。\n",
    "\n",
    "Word2Vec模型主要有两种训练方法：Skip-gram和CBOW（Continuous Bag of Words）。Skip-gram模型通过给定中心词来预测上下文词汇，而CBOW则通过给定上下文词汇来预测中心词。这两种方法都能够学习到词汇的分布式表示，这些表示可以用作后续自然语言处理任务（如情感分析、命名实体识别等）的输入特征。\n",
    "\n",
    "总之，Word2Vec通过将词汇转换为向量，有效地捕捉了词汇之间的语义信息，为自然语言处理提供了强大的工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10914c83-9764-45c4-a830-77dd1fb994fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **人话：**把文字转成向量，放到一个空间里，把近义词 尽量 放一块，把反义词/不相关的词 尽量 放远一些 ，有点像语义分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b120933-d455-4ca4-996a-94f1a9cd827e",
   "metadata": {},
   "source": [
    "# 2.怎么实现Word2Vec，有哪些步骤，这些步骤作用是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e54ae3-3c7d-4b01-9a44-7242c23b1f33",
   "metadata": {},
   "source": [
    "## 步骤1.数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ea512-1979-4827-81da-48e4198d71c8",
   "metadata": {},
   "source": [
    "作用：将原始文本数据转化为适合模型处理的格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f2f6f-d730-4572-9517-86c246b743d7",
   "metadata": {},
   "source": [
    "## 步骤2. 构建词汇表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e2906-6427-4ef9-80ef-6a87e88129ec",
   "metadata": {},
   "source": [
    "作用：创建一个将词汇映射到唯一索引的数据结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30657d-aec4-454b-8070-5065c7fe2701",
   "metadata": {},
   "source": [
    "## 步骤3. 生成训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba551d1-b8ed-46d0-8ca8-385ddec4b563",
   "metadata": {},
   "source": [
    "作用：根据词汇表和上下文窗口创建训练样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3781a6-67db-4a48-8288-00924eac1057",
   "metadata": {},
   "source": [
    "## 步骤4. 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19569fdd-74a5-4a02-83f4-ea869474b977",
   "metadata": {},
   "source": [
    "作用：建立神经网络模型以进行词向量学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d7459-936e-4a41-a0b3-1cedb10a1d0b",
   "metadata": {},
   "source": [
    "## 步骤5. 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c0d26-b635-4f34-a8e6-fbc2073f35a4",
   "metadata": {},
   "source": [
    "作用：优化模型参数以最小化预测误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd23c47-ddfe-41a2-b2bd-01f65a7d4e69",
   "metadata": {},
   "source": [
    "## 步骤6. 评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaaa9ba-1cad-47cf-a296-8949e5ad4f30",
   "metadata": {},
   "source": [
    "作用：检查模型的性能，并提取训练好的词向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733cd928-d87c-4502-b7a6-a66e87519a21",
   "metadata": {},
   "source": [
    "## 步骤7. 应用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa5a3c-b28b-4ab0-8437-a0decb9e6e1d",
   "metadata": {},
   "source": [
    "作用：将训练好的词向量应用于实际的自然语言处理任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4518e-e848-4d6c-bca9-64df8deac026",
   "metadata": {},
   "source": [
    "# 3.代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abee82-f985-46cf-a86c-62d3712d00a0",
   "metadata": {},
   "source": [
    "## 3.1 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63562f67-c1d6-4096-a0c8-183fc5029ce3",
   "metadata": {},
   "source": [
    "### 3.1.1 数据预处理\n",
    "    1.去除文本中的标点符号和特殊字符，保留中文、英文和空格。\n",
    "    2.将文本中的中文和英文分开处理，并将它们合并成一个单词列表。\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ce847-8d6a-4ecb-9920-c8674a20c966",
   "metadata": {},
   "source": [
    "#### **1.去除文本中的标点符号和特殊字符，保留中文、英文和空格。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dbd9d1a7-4af7-45ce-b9f0-c844141dc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 去除所有标点符号和特殊字符（保留中英文和空格）\n",
    "    text = re.sub(r'[^\\w\\s\\u4e00-\\u9fff]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19413c4-8d07-454a-a614-9e48c7bcc52a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **示例**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5305c7e2-c854-4105-93aa-551bf7d36862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理后的文本: 我喜欢吃苹果 and I like bananas too\n"
     ]
    }
   ],
   "source": [
    "# 示例文本\n",
    "text = \"我喜欢吃苹果, and I like bananas too!\"\n",
    "preprocessed_text = preprocess_text(text)\n",
    "#去除了符号\n",
    "print(\"预处理后的文本:\", preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65f9b3-4cd7-4471-bb8e-485bb79447da",
   "metadata": {},
   "source": [
    "#### **2.将文本中的中文和英文分开处理，并将它们合并成一个单词列表。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2205f360-a3d7-4963-95a4-3ae6990e8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    # 提取中文字符\n",
    "    chinese_text = re.findall(r'[\\u4e00-\\u9fff]+', text)\n",
    "    \n",
    "    # 中文字符分词（每个字符作为一个词）\n",
    "    chinese_tokens = []\n",
    "    for chunk in chinese_text:\n",
    "        for char in chunk:\n",
    "            chinese_tokens.append(char)\n",
    "\n",
    "    # 提取英文单词（包括连续的英文单词）\n",
    "    english_tokens = re.findall(r'[a-zA-Z]+', text)\n",
    "    \n",
    "    # 合并所有分词结果\n",
    "    all_tokens = chinese_tokens + english_tokens\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b797dd4-d239-4023-8f0b-e103ef4e3daa",
   "metadata": {},
   "source": [
    "##### **示例**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "73198089-c50a-4fff-aec1-4da71aa23612",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'english_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 示例文本\u001b[39;00m\n\u001b[0;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m我喜欢吃苹果，and I like bananas too!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m分词后的文本数据:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokens)\n",
      "Cell \u001b[1;32mIn[81], line 15\u001b[0m, in \u001b[0;36mtokenize_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     12\u001b[0m english_text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[a-zA-Z]+\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 合并所有分词结果\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m all_tokens \u001b[38;5;241m=\u001b[39m chinese_tokens \u001b[38;5;241m+\u001b[39m \u001b[43menglish_tokens\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_tokens\n",
      "\u001b[1;31mNameError\u001b[0m: name 'english_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# 示例文本\n",
    "text = \"我喜欢吃苹果，and I like bananas too!\"\n",
    "tokens = tokenize_text(text)\n",
    "print(\"分词后的文本数据:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10101599-c8a8-4c46-b0ed-f2cf0944c7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
